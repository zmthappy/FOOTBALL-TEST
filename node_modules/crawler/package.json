{
  "_from": "crawler@^1.4.0",
  "_id": "crawler@1.5.0",
  "_inBundle": false,
  "_integrity": "sha512-0iybajRv0RqIogn60CmglSZ3nmDEUs01cMqBF4ZdSNpYEtJEkEexDuxov/neHgYYrF+PDZnmVygRAkEd/SYIdA==",
  "_location": "/crawler",
  "_phantomChildren": {
    "boolbase": "1.0.0",
    "inherits": "2.0.4",
    "lodash.assignin": "4.2.0",
    "lodash.bind": "4.2.1",
    "lodash.defaults": "4.2.0",
    "lodash.filter": "4.6.0",
    "lodash.flatten": "4.4.0",
    "lodash.foreach": "4.5.0",
    "lodash.map": "4.6.0",
    "lodash.merge": "4.6.2",
    "lodash.pick": "4.4.0",
    "lodash.reduce": "4.6.0",
    "lodash.reject": "4.6.0",
    "lodash.some": "4.6.0",
    "readable-stream": "3.6.2",
    "safer-buffer": "2.1.2"
  },
  "_requested": {
    "type": "range",
    "registry": true,
    "raw": "crawler@^1.4.0",
    "name": "crawler",
    "escapedName": "crawler",
    "rawSpec": "^1.4.0",
    "saveSpec": null,
    "fetchSpec": "^1.4.0"
  },
  "_requiredBy": [
    "/"
  ],
  "_resolved": "https://registry.npmjs.org/crawler/-/crawler-1.5.0.tgz",
  "_shasum": "27fc8c80d2785b798e0f8fa59675401de4f4ff70",
  "_spec": "crawler@^1.4.0",
  "_where": "D:\\doanload\\vueProject\\newFootballJudge",
  "bugs": {
    "url": "https://github.com/bda-research/node-crawler/issues"
  },
  "bundleDependencies": false,
  "dependencies": {
    "bottleneckp": "~1.1.3",
    "cheerio": "^0.22.0",
    "iconv-lite": "^0.4.8",
    "lodash": "^4.17.10",
    "request": "~2.88.0",
    "seenreq": "^3.0.0",
    "type-is": "^1.6.14"
  },
  "deprecated": false,
  "description": "Crawler is a web spider written with Nodejs. It gives you the full power of jQuery on the server to parse a big number of pages as they are downloaded, asynchronously",
  "devDependencies": {
    "chai": "^4.2.0",
    "coveralls": "^3.0.2",
    "eslint": "^5.0.0",
    "jsdom": "^9.6.0",
    "mocha": "^6.1.0",
    "mocha-testdata": "^1.2.0",
    "nock": "^13.0.5",
    "nyc": "^13.1.0",
    "sinon": "^7.0.0",
    "whacko": "^0.19.1"
  },
  "directories": {
    "test": "tests"
  },
  "engine-strict": {
    "node": ">=10.0.0"
  },
  "homepage": "https://github.com/bda-research/node-crawler",
  "keywords": [
    "dom",
    "javascript",
    "crawling",
    "spider",
    "scraper",
    "scraping",
    "jquery",
    "crawler",
    "nodejs"
  ],
  "licenses": [
    {
      "type": "MIT",
      "url": "http://github.com/bda-research/node-crawler/blob/master/LICENSE.txt"
    }
  ],
  "main": "./lib/crawler.js",
  "name": "crawler",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/bda-research/node-crawler.git"
  },
  "scripts": {
    "cover": "nyc --reporter=lcovonly --reporter=text --reporter=text-summary mocha --timeout=15000 --reporter spec tests/*.test.js",
    "hint": "eslint ./lib/*.js ./tests/*.js",
    "http2test": "mocha --timeout=15000 tests/http2*.test.js",
    "test": "mocha --timeout=15000 tests/*.test.js"
  },
  "version": "1.5.0"
}
